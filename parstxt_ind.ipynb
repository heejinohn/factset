{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re, sys, pandas as pd\n",
    "TXT_DIR = '/Users/heejinohn/trantxt/txt'\n",
    "filename ='AIV_20170428.pdf.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with open(r'/Users/heejinohn/trantxt/master_csv.csv', 'r') as csvfile:\n",
    "#     for linenum, line in enumerate(csvfile):\n",
    "#         splitted_line = line.split(\",\")\n",
    "#         filename = splitted_line[1].rstrip()\n",
    "#         cusip = splitted_line[0].rstrip()\n",
    "#         print(linenum, filename, \" started.\")\n",
    "#####################################################################################\n",
    "# read in file\n",
    "#####################################################################################\n",
    "file = open(os.path.join(TXT_DIR, filename),'r')\n",
    "text = file.read()\n",
    "file.close()\n",
    "#####################################################################################\n",
    "# split lines \n",
    "#####################################################################################\n",
    "lines = [line.strip() for line in text.split('\\n')]\n",
    "lines = [' '.join(x.split()) for x in lines if x=='' or len(x) >= 3]\n",
    "if next(s for s in lines if s) == 'Corrected Transcript':\n",
    "    doc_error = 0\n",
    "    doc = next((x for x in lines if x.endswith('Transcript')), None)\n",
    "    pat1 = re.compile(r\"^(([0-9])|([0-2][0-9])|([3][0-1]))[- /.](Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[- /.](19|20)\\d\\d$\")\n",
    "    date = next((x for x in lines if pat1.match(x)), None)\n",
    "    pat2 = re.compile(r\"^(?:.*)\\s\\((?:[A-Z]+(?:\\.XX(?:[0-9]|1[0-9])|\\.[A-Z]+(?:\\.[A-Z]+)?|\\s?Q[0-5])?|[0-9A-Z]+\\-[A-Z])\\)$\")\n",
    "    comp = next((x for x in lines if pat2.match(x)), None)\n",
    "    pat4 = re.compile(r\"^((March|September|December|FY|Q[1-5])\\s+\\d{4}\\s+|Business Update)\")\n",
    "    evnt = next((x for x in lines if pat4.match(x)), None)\n",
    "    if comp is not None:\n",
    "        tic = comp[comp.find(\"(\")+1:comp.find(\")\")]\n",
    "    else:\n",
    "        tic = \"\"\n",
    "#####################################################################################\n",
    "# write doc file for documents other than corrected transcripts\n",
    "#####################################################################################\n",
    "# else:\n",
    "#     doc_error = 1\n",
    "#     doc = pd.DataFrame(data = [(cusip, 1, \"\", \"\")],index=[filename])\n",
    "#     doc.to_csv(r'/Users/heejinohn/trantxt/doc.csv', mode='a', header=False, sep='|')\n",
    "#     print('\\t', linenum, filename, ' completed.')\n",
    "# All subsequent codes apply only to documents identified as corrected transcripts.\n",
    "\n",
    "\n",
    "if doc_error == 0:\n",
    "#####################################################################################\n",
    "# remove clutters\n",
    "#####################################################################################\n",
    "    lines = [line for line in lines if line[:5]!=\"1-877\" \\\n",
    "             and line.split(' ', 1)[0]!='Copyright' \\\n",
    "             and line.split(':', 1)[0]!='Total Pages' \\\n",
    "             and line != date \\\n",
    "             and \"\".join(line.split()) != \"\".join(comp.split()) \\\n",
    "             and line != evnt \\\n",
    "             and line != doc \\\n",
    "             and line != \"(\"+tic+\")\"\n",
    "            ]\n",
    "    discl = len(lines) - 1 - lines[::-1].index('Disclaimer')\n",
    "    lines = lines[:discl]\n",
    "    from itertools import groupby\n",
    "    lines = [x[0] for x in groupby(lines)]\n",
    "    clean_txt = lines.copy()\n",
    "#####################################################################################\n",
    "# identify management:position\n",
    "#####################################################################################\n",
    "    # def chunks(l, n):\n",
    "    #     chunk=[]\n",
    "    #     \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    #     for i in range(0, len(l), n):\n",
    "    #         chunk.append(l[i:i + n])\n",
    "    #     return chunk\n",
    "\n",
    "    if \"CORPORATE PARTICIPANTS\" in clean_txt:\n",
    "        start = len(clean_txt) - 1 - clean_txt[::-1].index('CORPORATE PARTICIPANTS')\n",
    "        end = next(i for i, x in enumerate(clean_txt) if x.startswith('......') or x == 'OTHER PARTICIPANTS')\n",
    "        blanks = [i for i, x in enumerate(clean_txt[start:end]) if x=='']\n",
    "        mgmt_names =[clean_txt[start:end][blanks[i]+1] for i in range(len(blanks)-1)]\n",
    "        mgmt_pos = []\n",
    "        for i in range(len(blanks)-1):\n",
    "            if blanks[i+1] - blanks[i]==3:\n",
    "                mgmt_pos.append(clean_txt[start:end][blanks[i]+2])\n",
    "            else:\n",
    "                pos = \" \".join(clean_txt[start:end][blanks[i]+2:blanks[i+1]])\n",
    "                mgmt_pos.append(pos)\n",
    "        mgmt_error = 0\n",
    "        del clean_txt[:end + 1]\n",
    "#         mgmt = pd.DataFrame(data = list(zip(mgmt_names,mgmt_pos)), index = [[filename] * len(mgmt_names), list(range(len(mgmt_names)))])\n",
    "#         mgmt.to_csv(r'/Users/heejinohn/trantxt/mgmt.csv', mode='a', header=False, sep='|')\n",
    "    else:\n",
    "        mgmt_error = 1\n",
    "#         mgmt = pd.DataFrame(data = [(\"\", 1, \"\", \"\")],index=[filename])\n",
    "#         mgmt.to_csv(r'/Users/heejinohn/trantxt/mgmt.csv', mode='a', header=False, sep='|')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# identify analyst:firm\n",
    "#####################################################################################\n",
    "if \"OTHER PARTICIPANTS\" in clean_txt:\n",
    "    start = len(clean_txt) - 1 - clean_txt[::-1].index('OTHER PARTICIPANTS')\n",
    "    end = next(i for i, x in enumerate(clean_txt) if x.startswith('......') or x == 'MANAGEMENT DISCUSSION SECTION')\n",
    "    blanks = [i for i, x in enumerate(clean_txt[start:end]) if x=='']\n",
    "    analyst_names =[clean_txt[start:end][blanks[i]+1] for i in range(len(blanks)-1)]\n",
    "    analyst_emps = []\n",
    "    for i in range(len(blanks)-1):\n",
    "        if blanks[i+1] - blanks[i]==3:\n",
    "            analyst_emps.append(clean_txt[start:end][blanks[i]+2])\n",
    "        else:\n",
    "            pos = \" \".join(clean_txt[start:end][blanks[i]+2:blanks[i+1]])\n",
    "            analyst_emps.append(pos)\n",
    "    analyst_error = 0\n",
    "    del clean_txt[:end + 1]\n",
    "#         analyst = pd.DataFrame(data = list(zip(analyst_names,analyst_emps)), index = [[filename] * len(analyst_names), list(range(len(analyst_names)))])\n",
    "#         analyst.to_csv(r'/Users/heejinohn/trantxt/analysts.csv', mode='a', header=False, sep='|')\n",
    "else:\n",
    "    analyst_error = 1\n",
    "    analyst_names = []\n",
    "#         analyst = pd.DataFrame(data = [(\"\", 1, \"\", \"\")],index=[filename])\n",
    "#         analyst.to_csv(r'/Users/heejinohn/trantxt/analysts.csv', mode='a', header=False, sep='|')\n",
    "#####################################################################################\n",
    "# remove operator dialogues\n",
    "#####################################################################################\n",
    "clean_txt = [i for i in clean_txt if i != \"\"]\n",
    "operators = [i for i, x in enumerate(clean_txt) if x[:9] == \"Operator:\"]\n",
    "splits = [i for i, x in enumerate(clean_txt) if x.startswith('......') or x in analyst_names + mgmt_names]\n",
    "drops = [[x,next((i for i in splits if i > x), None)] for x in operators]\n",
    "for x in drops[::-1]:\n",
    "    if x[1] == None:\n",
    "        del clean_txt[x[0]:]\n",
    "    else:\n",
    "        if x[1]-x[0]==1:\n",
    "            del clean_txt[x[0]]\n",
    "        else:\n",
    "            del clean_txt[x[0]:x[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# divide management discussion and question and answer sections\n",
    "#####################################################################################\n",
    "if 'QUESTION AND ANSWER SECTION' in clean_txt:\n",
    "    sec = clean_txt.index('QUESTION AND ANSWER SECTION')\n",
    "    mds = clean_txt[:sec]\n",
    "    qnas = clean_txt[sec + 1:]\n",
    "    qnas_error = 0\n",
    "else:\n",
    "    mds = clean_txt\n",
    "    qna_clean_txt = \"\"\n",
    "    qnas_error = 1\n",
    "#####################################################################################\n",
    "# clean management discussion section\n",
    "#####################################################################################\n",
    "mds_clean = [x for x in mds if x not in mgmt_names \\\n",
    "            and x not in mgmt_pos \\\n",
    "            and not x.startswith('......') \\\n",
    "            and (x != x.upper() or not re.search('[a-zA-Z]', x))]\n",
    "mds_clean_txt = \" \".join(mds_clean)\n",
    "#####################################################################################\n",
    "# write doc file for corrected transcripts\n",
    "#####################################################################################\n",
    "#     doc = pd.DataFrame(data = [(cusip, doc_error, qnas_error, mds_clean_txt)],index=[filename])\n",
    "#     doc.to_csv(r'/Users/heejinohn/trantxt/doc.csv', mode='a', header=False, sep='|')\n",
    "#####################################################################################\n",
    "# clean question and answer section\n",
    "#####################################################################################\n",
    "if mgmt_error == 0 and analyst_error == 0 and qnas_error == 0:\n",
    "    qnas_clean = [x for x in qnas if x.startswith('.......') \\\n",
    "                  or x.upper() != x or not re.search('[a-zA-Z]', x)]\n",
    "    qnas_clean = [x for x in qnas_clean if x not in mgmt_pos and x not in analyst_emps]\n",
    "    for n, i in enumerate(qnas_clean):\n",
    "        if i.startswith('<'):\n",
    "            if ':' in i:\n",
    "                qnas_clean.insert(n+1, i.split(':',1)[1])\n",
    "                split_i = i.split(':',1)[0]\n",
    "            elif ']' in i:\n",
    "                qnas_clean.insert(n+1, i.split(']',1)[1])\n",
    "                split_i = i.split(']',1)[0]\n",
    "            else:\n",
    "                split_i = i\n",
    "            capped = set(re.findall(r'(\\b[A-Z][a-zA-Z\\'\\-]+\\b)', split_i))\n",
    "            if not capped:\n",
    "                capped = set(re.findall(r'(\\b[A-Z][a-zA-Z\\'\\-]+\\b)', i))\n",
    "            a_last = [i[-1] for i in [i.split() for i in analyst_names]]\n",
    "            a_first = [j for fullname in analyst_names for j in fullname.split()[:-1]]\n",
    "            m_last = [i[-1] for i in [i.split() for i in mgmt_names]]\n",
    "            m_first = [j for fullname in mgmt_names for j in fullname.split()[:-1]]\n",
    "            if capped&set(a_last) and not capped&set(m_last):\n",
    "                if len(capped&set(a_last)) == 1:\n",
    "                    qnas_clean[n] = analyst_names[a_last.index(next(iter(capped&set(a_last))))]\n",
    "                else:\n",
    "                    qnas_clean[n] = analyst_names[a_first.index(next(iter(capped&set(a_first))))]\n",
    "            elif capped&set(m_last) and not capped&set(a_last):\n",
    "                if len(capped&set(m_last)) == 1:\n",
    "                    qnas_clean[n] = mgmt_names[m_last.index(next(iter(capped&set(m_last))))]\n",
    "                else:\n",
    "                    qnas_clean[n] = mgmt_names[m_first.index(next(iter(capped&set(m_first))))]\n",
    "            else:\n",
    "                if capped&set(a_first):\n",
    "                    qnas_clean[n] = analyst_names[a_last.index(next(iter(capped&set(a_last))))]\n",
    "                elif capped&set(m_first):\n",
    "                    qnas_clean[n] = mgmt_names[m_last.index(next(iter(capped&set(m_last))))]\n",
    "\n",
    "    splits = [i for i, x in enumerate(qnas_clean) if x.startswith('......')]\n",
    "    mgmt_locs = [i for i, x in enumerate(qnas_clean) if x in mgmt_names]\n",
    "    analyst_locs = [i for i, x in enumerate(qnas_clean) if x in analyst_names]\n",
    "    sides = []\n",
    "    for split in splits:\n",
    "        if split == 0:\n",
    "            sides.append(split + 1)\n",
    "        else:\n",
    "            sides.extend([split - 1, split + 1])\n",
    "    add_splits = [x for x in list(set(mgmt_locs)-set(sides))+list(set(analyst_locs)-set(sides))]\n",
    "    combines = sorted(splits + add_splits)\n",
    "    qna_clean_txt = []\n",
    "    for i in range(len(combines)-1):\n",
    "        if combines[i] in splits and combines[i+1]-combines[i] > 1:\n",
    "            qna_clean_txt.append(qnas_clean[combines[i]+1])\n",
    "            qna_clean_txt.append(\" \".join(qnas_clean[combines[i]+2:combines[i+1]]))\n",
    "        elif combines[i] in add_splits and combines[i+1]-combines[i] > 1:\n",
    "            qna_clean_txt.append(qnas_clean[combines[i]])\n",
    "            qna_clean_txt.append(\" \".join(qnas_clean[combines[i]+1:combines[i+1]]))\n",
    "    if combines[-1] != len(qnas_clean):\n",
    "        if combines[-1] in splits and len(qnas_clean)-combines[-1] > 1:\n",
    "            qna_clean_txt.append(qnas_clean[combines[-1]+1])\n",
    "            qna_clean_txt.append(\" \".join(qnas_clean[combines[-1]+2:]))\n",
    "        elif combines[-1] in add_splits and len(qnas_clean)-combines[-1] > 1:\n",
    "            qna_clean_txt.append(qnas_clean[combines[-1]])\n",
    "            qna_clean_txt.append(\" \".join(qnas_clean[combines[-1]+1:]))\n",
    "    an_emp = dict(zip(analyst_names, analyst_emps))\n",
    "    an_loc = {analyst:qna_clean_txt.index(analyst) for analyst in analyst_names if analyst in qna_clean_txt}\n",
    "    analyst_names = sorted(analyst_names, key = lambda x: (x not in an_loc, an_loc.get(x, None)))\n",
    "    analyst_emp = [an_emp[name] for name in analyst_names]\n",
    "    q = dict()\n",
    "    l = dict()\n",
    "\n",
    "    for i, name in enumerate(analyst_names):\n",
    "        q[i] = [qna_clean_txt[j+1] for j, line in enumerate(qna_clean_txt) if line == name]\n",
    "        l[i] = [j+1 for j, line in enumerate(qna_clean_txt) if line == name]\n",
    "    a = {k: [] for k in list(l.keys())}\n",
    "\n",
    "    for key in l.keys():\n",
    "        if len(l[key]) > 0:\n",
    "            others = [name for i, name in enumerate(analyst_names) if i != key]\n",
    "            for n, loc in enumerate(l[key][:-1]):\n",
    "                end = min(l[key][n+1], next((i for i, line in enumerate(qna_clean_txt) if line in others and i > loc), len(qna_clean_txt)))\n",
    "                if any(x in mgmt_names for x in qna_clean_txt[loc:end]):\n",
    "                    a[key].append(\" \".join([qna_clean_txt[loc:end][j+1] for j,line in enumerate(qna_clean_txt[loc:end]) if line in mgmt_names]))\n",
    "                else:\n",
    "                    a[key].append(\"\")\n",
    "            if l[key][-1] == max(value for values in l.values() for value in values):\n",
    "                if len([x for x in q[key][-1].split(\". \") if not re.search(r'[T|t]hanks?(?:\\syou)?|appreciate|[O|o]kay|[G|g]ood|[G|g]reat|[Y|y]eah', x)]) < 3:\n",
    "                    a[key].append(\"\")\n",
    "                else:\n",
    "                    if any(x in mgmt_names for x in qna_clean_txt[l[key][-1]:]):\n",
    "                        a[key].append(\" \".join([qna_clean_txt[l[key][-1]:][j+1] for j,line in enumerate(qna_clean_txt[l[key][-1]:]) if line in mgmt_names]))\n",
    "                    else:\n",
    "                        a[key].append(\"\")\n",
    "            else:\n",
    "                end = next(i for i, line in enumerate(qna_clean_txt) if line in others and i > l[key][-1])\n",
    "                if any(x in mgmt_names for x in qna_clean_txt[l[key][-1]:end]):\n",
    "                    a[key].append(\" \".join([qna_clean_txt[l[key][-1]:end][j+1] for j,line in enumerate(qna_clean_txt[l[key][-1]:end]) if line in mgmt_names]))\n",
    "                else:\n",
    "                    a[key].append(\"\")\n",
    "#####################################################################################\n",
    "# write qna file\n",
    "#####################################################################################                            \n",
    "#         index = pd.MultiIndex.from_tuples([(filename, key, i) for key in q for i in range(len(q[key]))])\n",
    "#         qa = pd.DataFrame(index = index, columns =['q', 'a'])\n",
    "#         for key in q:\n",
    "#             if len(q[key]) > 0:\n",
    "#                 for i in range(len(q[key])):\n",
    "#                     qa.at[(filename, key, i), \"q\"] = q[key][i]\n",
    "#                     qa.at[(filename, key, i), \"a\"] = a[key][i]\n",
    "#         qa.to_csv(r'/Users/heejinohn/trantxt/qna.csv', mode='a', header=False, sep='|')\n",
    "#####################################################################################\n",
    "# clean slate\n",
    "#####################################################################################                                            \n",
    "#     for name in dir():\n",
    "#         if name in ['doc', 'mgmt', 'analyst', 'qa']:\n",
    "#             del globals() [name]\n",
    "#     print('\\t', linenum, filename, ' completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyst = pd.DataFrame(data = list(zip(analyst_names,analyst_emps)), index = [[filename] * len(analyst_names), list(range(len(analyst_names)))])\n",
    "analyst.to_csv(r'/Users/heejinohn/trantxt/analysts_error.csv', mode='a', header=False, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_tuples([(filename, key, i) for key in q for i in range(len(q[key]))])\n",
    "qa = pd.DataFrame(index = index, columns =['q', 'a'])\n",
    "for key in q:\n",
    "    if len(q[key]) > 0:\n",
    "        for i in range(len(q[key])):\n",
    "            qa.at[(filename, key, i), \"q\"] = q[key][i]\n",
    "            qa.at[(filename, key, i), \"a\"] = a[key][i]\n",
    "qa.to_csv(r'/Users/heejinohn/trantxt/qna_error.csv', mode='a', header=False, sep='|')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
